import { defineStore } from 'pinia'
import { ref, computed } from 'vue'
import type { VideoSource, AnalysisResult, AnalysisType } from '@/types'
import { WebRTCClient, type WebRTCConfig } from '@/utils/webrtc'

export const useVideoStore = defineStore('video', () => {
  // çŠ¶æ€
  const videoSources = ref<VideoSource[]>([])
  const analysisResults = ref<AnalysisResult[]>([])
  const analysisTypes = ref<AnalysisType[]>([
    { id: 'object_detection', name: 'ç›®æ ‡æ£€æµ‹', enabled: true },
    { id: 'instance_segmentation', name: 'å®ä¾‹åˆ†å‰²', enabled: false }
  ])

  const selectedSourceId = ref<string>('')
  const selectedAnalysisType = ref<string>('object_detection')

  const wsConnection = ref<WebSocket | null>(null)
  const connectionStatus = ref<'connecting' | 'connected' | 'disconnected'>('disconnected')

  // WebRTCç›¸å…³çŠ¶æ€
  const webrtcClient = ref<WebRTCClient | null>(null)
  const webrtcConnected = ref(false)
  const videoStream = ref<MediaStream | null>(null)
  const currentVideoElement = ref<HTMLVideoElement | null>(null)

  // JPEGè§†é¢‘æ’­æ”¾å™¨çŠ¶æ€
  const jpegVideoPlayer = ref<any>(null) // JpegVideoPlayerç»„ä»¶å¼•ç”¨
  const lastFrameTimestamp = ref(0)
  const frameLatency = ref(0)

  // è®¡ç®—å±æ€§
  const activeVideoSources = computed(() =>
    videoSources.value.filter(source => source.status === 'active')
  )

  const selectedSource = computed(() =>
    videoSources.value.find(source => source.id === selectedSourceId.value)
  )

  const recentAnalysisResults = computed(() =>
    analysisResults.value
      .filter(result => result.source_id === selectedSourceId.value)
      .sort((a, b) => b.timestamp - a.timestamp)
      .slice(0, 10)
  )

  // æ–¹æ³•
  const connectWebSocket = () => {
    // ç®€åŒ–å®ç°ï¼šç›´æ¥è®¾ç½®ä¸ºå·²è¿æ¥ï¼Œå› ä¸ºåç«¯æ²¡æœ‰å®ç°æ§åˆ¶WebSocket
    connectionStatus.value = 'connected'
    console.log('æ¨¡æ‹ŸWebSocketè¿æ¥å·²å»ºç«‹')
  }

  const handleWebSocketMessage = (message: any) => {
    switch (message.type) {
      case 'video_sources_update':
        videoSources.value = message.data
        break

      case 'analysis_result':
        analysisResults.value.unshift(message.data)
        // ä¿æŒæœ€å¤š1000ä¸ªç»“æœ
        if (analysisResults.value.length > 1000) {
          analysisResults.value = analysisResults.value.slice(0, 1000)
        }
        break

      case 'status_update':
        updateVideoSourceStatus(message.source_id, message.data.status)
        break

      case 'error':
        console.error('ç³»ç»Ÿé”™è¯¯:', message.data)
        break

      default:
        console.log('æœªçŸ¥æ¶ˆæ¯ç±»å‹:', message)
    }
  }

  const updateVideoSourceStatus = (sourceId: string, status: string) => {
    const source = videoSources.value.find(s => s.id === sourceId)
    if (source) {
      source.status = status as VideoSource['status']
    }
  }

  const addVideoSource = (source: Omit<VideoSource, 'id' | 'status'>) => {
    const newSource: VideoSource = {
      ...source,
      id: `source_${Date.now()}`,
      status: 'active'
    }
    videoSources.value.push(newSource)
    console.log('æ·»åŠ è§†é¢‘æº:', newSource.name)
  }

  const removeVideoSource = (sourceId: string) => {
    const index = videoSources.value.findIndex(s => s.id === sourceId)
    if (index > -1) {
      videoSources.value.splice(index, 1)

      // å‘é€åˆ°åç«¯
      if (wsConnection.value && wsConnection.value.readyState === WebSocket.OPEN) {
        wsConnection.value.send(JSON.stringify({
          type: 'remove_video_source',
          data: { source_id: sourceId }
        }))
      }
    }
  }

  const startAnalysis = (sourceId: string, analysisType: string) => {
    console.log('å¼€å§‹åˆ†æ:', sourceId, analysisType)
    // ç®€åŒ–å®ç°ï¼šç›´æ¥é€šè¿‡WebRTCè¯·æ±‚è§†é¢‘æµ
    requestVideoStream()
  }

  const stopAnalysis = (sourceId: string) => {
    console.log('åœæ­¢åˆ†æ:', sourceId)
  }

  const setSelectedSource = (sourceId: string) => {
    selectedSourceId.value = sourceId
  }

  const setSelectedAnalysisType = (analysisType: string) => {
    selectedAnalysisType.value = analysisType
  }

  // WebRTCç›¸å…³æ–¹æ³•
  const initWebRTC = () => {
    const config: WebRTCConfig = {
      signalingServerUrl: 'ws://localhost:8083',
      stunServers: []  // çº¯æœ¬åœ°è¿æ¥ï¼Œä¸ä½¿ç”¨STUN/TURN
    }

    webrtcClient.value = new WebRTCClient(config)

    webrtcClient.value.setEventHandlers({
      onConnected: () => {
        webrtcConnected.value = true
        console.log('WebRTCè¿æ¥å»ºç«‹')
      },
      onDisconnected: () => {
        webrtcConnected.value = false
        videoStream.value = null
        console.log('WebRTCè¿æ¥æ–­å¼€')
      },
      onVideoStream: (stream: MediaStream) => {
        videoStream.value = stream
        if (currentVideoElement.value) {
          currentVideoElement.value.srcObject = stream
        }
        console.log('æ¥æ”¶åˆ°è§†é¢‘æµ')
      },
      onJpegFrame: (jpegData: ArrayBuffer) => {
        handleJpegFrame(jpegData)
      },
      onError: (error: string) => {
        console.error('WebRTCé”™è¯¯:', error)
      }
    })
  }

  const connectWebRTC = async () => {
    if (!webrtcClient.value) {
      initWebRTC()
    }

    try {
      const success = await webrtcClient.value?.connect()
      if (success) {
        console.log('WebRTCä¿¡ä»¤è¿æ¥æˆåŠŸ')
      }
    } catch (error) {
      console.error('WebRTCè¿æ¥å¤±è´¥:', error)
    }
  }

  const disconnectWebRTC = () => {
    webrtcClient.value?.disconnect()
    webrtcClient.value = null
    webrtcConnected.value = false
    videoStream.value = null
  }

  const setVideoElement = (element: HTMLVideoElement) => {
    console.log('ğŸ“¹ videoStore.setVideoElementè¢«è°ƒç”¨, element:', element)
    currentVideoElement.value = element
    if (webrtcClient.value) {
      console.log('âœ… webrtcClientå­˜åœ¨ï¼Œæ­£åœ¨è®¾ç½®è§†é¢‘å…ƒç´ ')
      webrtcClient.value.setVideoElement(element)
    } else {
      console.log('âš ï¸ webrtcClientä¸å­˜åœ¨ï¼Œæ— æ³•è®¾ç½®è§†é¢‘å…ƒç´ ')
    }
  }

  const requestVideoStream = () => {
    console.log('ğŸ¬ è¯·æ±‚è§†é¢‘æµ - webrtcClient:', !!webrtcClient.value, 'selectedSourceId:', selectedSourceId.value)
    if (webrtcClient.value && selectedSourceId.value) {
      console.log('âœ… æ¡ä»¶æ»¡è¶³ï¼Œå‘é€request_offer')
      webrtcClient.value.requestVideoStream()
    } else {
      console.log('âŒ æ¡ä»¶ä¸æ»¡è¶³ - webrtcClientå­˜åœ¨:', !!webrtcClient.value, 'selectedSourceIdå­˜åœ¨:', !!selectedSourceId.value)
    }
  }

  // JPEGè§†é¢‘æ’­æ”¾å™¨ç›¸å…³æ–¹æ³•
  const setJpegVideoPlayer = (player: any) => {
    jpegVideoPlayer.value = player
    console.log('ğŸ¬ è®¾ç½®JPEGè§†é¢‘æ’­æ”¾å™¨:', !!player)
  }

  const handleJpegFrame = (jpegData: ArrayBuffer) => {
    const currentTime = performance.now()

    // è®¡ç®—å»¶è¿Ÿ
    if (lastFrameTimestamp.value > 0) {
      frameLatency.value = currentTime - lastFrameTimestamp.value
    }
    lastFrameTimestamp.value = currentTime

    console.log('ğŸ–¼ï¸ æ”¶åˆ°JPEGå¸§ï¼Œå¤§å°:', jpegData.byteLength, 'bytes')

    // å‘é€åˆ°JPEGæ’­æ”¾å™¨
    if (jpegVideoPlayer.value) {
      jpegVideoPlayer.value.displayJpegFrame(jpegData)
      jpegVideoPlayer.value.updateLatency(frameLatency.value)

      // æ›´æ–°åˆ†æç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
      const recentResult = recentAnalysisResults.value[0]
      if (recentResult) {
        jpegVideoPlayer.value.updateDetections(recentResult.detections || [])
      }
    } else {
      console.warn('âš ï¸ JPEGè§†é¢‘æ’­æ”¾å™¨æœªè®¾ç½®')
    }
  }

  // åˆå§‹åŒ–
  const init = () => {
    // æ·»åŠ ä¸€äº›ç¤ºä¾‹è§†é¢‘æº
    videoSources.value = [
      {
        id: 'camera_01',
        name: 'æ‘„åƒå¤´ 1',
        type: 'camera',
        url: '/dev/video0',
        status: 'active',
        fps: 30,
        resolution: '1280x720'
      },
      {
        id: 'file_01',
        name: 'æµ‹è¯•è§†é¢‘',
        type: 'file',
        url: 'test_video.mp4',
        status: 'inactive',
        fps: 25,
        resolution: '1920x1080'
      }
    ]

    if (videoSources.value.length > 0) {
      selectedSourceId.value = videoSources.value[0].id
    }

    // åˆå§‹åŒ–WebSocketç”¨äºæ§åˆ¶å‘½ä»¤ï¼ŒWebRTCç”¨äºè§†é¢‘æµ
    console.log('ğŸš€ videoStore.init() - å¼€å§‹åˆå§‹åŒ–')
    connectWebSocket()
    console.log('ğŸ¯ æ­£åœ¨è¿æ¥WebRTC...')
    connectWebRTC()
    console.log('âœ… videoStore.init() - åˆå§‹åŒ–å®Œæˆ')
  }

  return {
    // çŠ¶æ€
    videoSources,
    analysisResults,
    analysisTypes,
    selectedSourceId,
    selectedAnalysisType,
    connectionStatus,

    // WebRTCçŠ¶æ€
    webrtcConnected,
    videoStream,
    currentVideoElement,

    // è®¡ç®—å±æ€§
    activeVideoSources,
    selectedSource,
    recentAnalysisResults,

    // æ–¹æ³•
    connectWebSocket,
    addVideoSource,
    removeVideoSource,
    startAnalysis,
    stopAnalysis,
    setSelectedSource,
    setSelectedAnalysisType,

    // WebRTCæ–¹æ³•
    connectWebRTC,
    disconnectWebRTC,
    setVideoElement,
    requestVideoStream,

    // JPEGæ’­æ”¾å™¨æ–¹æ³•
    setJpegVideoPlayer,
    handleJpegFrame,

    init
  }
})