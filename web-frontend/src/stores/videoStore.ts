import { defineStore } from 'pinia'
import { ref, computed } from 'vue'
import type { VideoSource, AnalysisResult, AnalysisType } from '@/types'
import { WebRTCClient, type WebRTCConfig } from '@/utils/webrtc'

// æ¨¡å‹ä¿¡æ¯æ¥å£
interface ModelInfo {
  id: string
  name: string
  type: string
  status: 'loaded' | 'available' | 'loading' | 'error'
  description?: string
}

export const useVideoStore = defineStore('video', () => {
  // çŠ¶æ€
  const videoSources = ref<VideoSource[]>([])
  const analysisResults = ref<AnalysisResult[]>([])
  const analysisTypes = ref<AnalysisType[]>([
    { id: 'object_detection', name: 'ç›®æ ‡æ£€æµ‹', enabled: true },
    { id: 'instance_segmentation', name: 'å®ä¾‹åˆ†å‰²', enabled: false }
  ])

  const selectedSourceId = ref<string>('')
  const selectedAnalysisType = ref<string>('object_detection')

  // æ¨¡å‹ç›¸å…³çŠ¶æ€
  const availableModels = ref<ModelInfo[]>([])
  const selectedModelId = ref<string>('')
  const isAnalyzing = ref(true)

  const wsConnection = ref<WebSocket | null>(null)
  const connectionStatus = ref<'connecting' | 'connected' | 'disconnected'>('disconnected')

  // WebRTCç›¸å…³çŠ¶æ€
  const webrtcClient = ref<WebRTCClient | null>(null)
  const webrtcConnected = ref(false)
  const videoStream = ref<MediaStream | null>(null)
  const currentVideoElement = ref<HTMLVideoElement | null>(null)

  // JPEGè§†é¢‘æ’­æ”¾å™¨çŠ¶æ€
  const jpegVideoPlayer = ref<any>(null) // JpegVideoPlayerç»„ä»¶å¼•ç”¨
  const lastFrameTimestamp = ref(0)
  const frameLatency = ref(0)

  // è®¡ç®—å±æ€§
  const activeVideoSources = computed(() =>
    videoSources.value.filter(source => source.status === 'active')
  )

  const selectedSource = computed(() =>
    videoSources.value.find(source => source.id === selectedSourceId.value)
  )

  const recentAnalysisResults = computed(() =>
    analysisResults.value
      .filter(result => result.source_id === selectedSourceId.value)
      .sort((a, b) => b.timestamp - a.timestamp)
      .slice(0, 10)
  )

  // æ ¹æ®é€‰ä¸­çš„åˆ†æç±»å‹è¿‡æ»¤æ¨¡å‹
  const filteredModels = computed(() =>
    availableModels.value.filter(model => model.type === selectedAnalysisType.value)
  )

  // æ–¹æ³•
  const connectWebSocket = () => {
    // ç®€åŒ–å®ç°ï¼šç›´æ¥è®¾ç½®ä¸ºå·²è¿æ¥ï¼Œå› ä¸ºåç«¯æ²¡æœ‰å®ç°æ§åˆ¶WebSocket
    connectionStatus.value = 'connected'
    console.log('æ¨¡æ‹ŸWebSocketè¿æ¥å·²å»ºç«‹')
  }

  const handleWebSocketMessage = (message: any) => {
    switch (message.type) {
      case 'video_sources_update':
        videoSources.value = message.data
        break

      case 'analysis_result':
        analysisResults.value.unshift(message.data)
        // ä¿æŒæœ€å¤š1000ä¸ªç»“æœ
        if (analysisResults.value.length > 1000) {
          analysisResults.value = analysisResults.value.slice(0, 1000)
        }
        break

      case 'status_update':
        updateVideoSourceStatus(message.source_id, message.data.status)
        break

      case 'error':
        console.error('ç³»ç»Ÿé”™è¯¯:', message.data)
        break

      default:
        console.log('æœªçŸ¥æ¶ˆæ¯ç±»å‹:', message)
    }
  }

  const updateVideoSourceStatus = (sourceId: string, status: string) => {
    const source = videoSources.value.find(s => s.id === sourceId)
    if (source) {
      source.status = status as VideoSource['status']
    }
  }

  const addVideoSource = (source: Omit<VideoSource, 'id' | 'status'>) => {
    const newSource: VideoSource = {
      ...source,
      id: `source_${Date.now()}`,
      status: 'active'
    }
    videoSources.value.push(newSource)
    console.log('æ·»åŠ è§†é¢‘æº:', newSource.name)
  }

  const updateVideoSource = (source: VideoSource) => {
    const index = videoSources.value.findIndex(s => s.id === source.id)
    if (index > -1) {
      videoSources.value[index] = source
      console.log('æ›´æ–°è§†é¢‘æº:', source.name)
    }
  }

  const removeVideoSource = (sourceId: string) => {
    const index = videoSources.value.findIndex(s => s.id === sourceId)
    if (index > -1) {
      videoSources.value.splice(index, 1)

      // å‘é€åˆ°åç«¯
      if (wsConnection.value && wsConnection.value.readyState === WebSocket.OPEN) {
        wsConnection.value.send(JSON.stringify({
          type: 'remove_video_source',
          data: { source_id: sourceId }
        }))
      }
    }
  }

  const setSelectedModel = (modelId: string) => {
    selectedModelId.value = modelId
  }

  const getAnalysisStatus = async () => {
    // ç®€åŒ–å®ç°ï¼šè¿”å›å½“å‰çŠ¶æ€
    return {
      isAnalyzing: isAnalyzing.value,
      selectedSourceId: selectedSourceId.value,
      selectedModelId: selectedModelId.value
    }
  }

  const startAnalysis = async (sourceId: string, analysisType: string) => {
    console.log('å¼€å§‹åˆ†æ:', sourceId, analysisType, 'model_id:', selectedModelId.value)

    try {
      // ç¡®ä¿æœ‰é€‰ä¸­çš„æ¨¡å‹ID
      if (!selectedModelId.value) {
        throw new Error('è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ¨¡å‹')
      }

      // é€šè¿‡HTTP APIå‘é€å¯ç”¨æ£€æµ‹æ¡†ç»˜åˆ¶çš„è¯·æ±‚
      const response = await fetch('/api/analyzer/analysis/start', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          source_id: sourceId,
          model_id: selectedModelId.value,
          analysis_type: analysisType
        })
      })

      console.log('APIå“åº”çŠ¶æ€:', response.status, response.statusText)

      // æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©º
      const text = await response.text()
      console.log('APIå“åº”å†…å®¹:', text)

      if (!text) {
        throw new Error('æœåŠ¡å™¨è¿”å›ç©ºå“åº”')
      }

      const data = JSON.parse(text)
      if (data.success) {
        isAnalyzing.value = true
        console.log('âœ… å¯ç”¨åˆ†ææˆåŠŸ')
        // å¦‚æœWebRTCæœªè¿æ¥ï¼Œè¯·æ±‚è§†é¢‘æµ
        if (!webrtcConnected.value) {
          requestVideoStream()
        }
      } else {
        console.error('âŒ å¯ç”¨åˆ†æå¤±è´¥:', data.message)
        throw new Error(data.message || 'å¯ç”¨åˆ†æå¤±è´¥')
      }
    } catch (error) {
      console.error('âŒ å¯ç”¨åˆ†æè¯·æ±‚å¤±è´¥:', error)
      throw error
    }
  }

  const stopAnalysis = async (sourceId: string) => {
    console.log('åœæ­¢åˆ†æ:', sourceId)

    try {
      // é€šè¿‡HTTP APIå‘é€ç¦ç”¨æ£€æµ‹æ¡†ç»˜åˆ¶çš„è¯·æ±‚
      const response = await fetch('/api/analyzer/analysis/stop', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          source_id: sourceId
        })
      })

      console.log('APIå“åº”çŠ¶æ€:', response.status, response.statusText)

      // æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©º
      const text = await response.text()
      console.log('APIå“åº”å†…å®¹:', text)

      if (!text) {
        throw new Error('æœåŠ¡å™¨è¿”å›ç©ºå“åº”')
      }

      const data = JSON.parse(text)
      if (data.success) {
        isAnalyzing.value = false
        console.log('âœ… åœæ­¢åˆ†ææˆåŠŸ')
      } else {
        console.error('âŒ åœæ­¢åˆ†æå¤±è´¥:', data.message)
        throw new Error(data.message || 'åœæ­¢åˆ†æå¤±è´¥')
      }
    } catch (error) {
      console.error('âŒ åœæ­¢åˆ†æè¯·æ±‚å¤±è´¥:', error)
      throw error
    }
  }

  const setSelectedSource = (sourceId: string) => {
    selectedSourceId.value = sourceId
  }

  const setSelectedAnalysisType = (analysisType: string) => {
    selectedAnalysisType.value = analysisType
  }

  // WebRTCç›¸å…³æ–¹æ³•
  const initWebRTC = () => {
    const config: WebRTCConfig = {
      signalingServerUrl: 'ws://localhost:8083',
      stunServers: []  // çº¯æœ¬åœ°è¿æ¥ï¼Œä¸ä½¿ç”¨STUN/TURN
    }

    webrtcClient.value = new WebRTCClient(config)

    webrtcClient.value.setEventHandlers({
      onConnected: () => {
        webrtcConnected.value = true
        console.log('WebRTCè¿æ¥å»ºç«‹')
      },
      onDisconnected: () => {
        webrtcConnected.value = false
        videoStream.value = null
        console.log('WebRTCè¿æ¥æ–­å¼€')
      },
      onVideoStream: (stream: MediaStream) => {
        videoStream.value = stream
        if (currentVideoElement.value) {
          currentVideoElement.value.srcObject = stream
        }
        console.log('æ¥æ”¶åˆ°è§†é¢‘æµ')
      },
      onJpegFrame: (jpegData: ArrayBuffer) => {
        handleJpegFrame(jpegData)
      },
      onError: (error: string) => {
        console.error('WebRTCé”™è¯¯:', error)
      }
    })
  }

  const connectWebRTC = async () => {
    if (!webrtcClient.value) {
      initWebRTC()
    }

    try {
      const success = await webrtcClient.value?.connect()
      if (success) {
        console.log('WebRTCä¿¡ä»¤è¿æ¥æˆåŠŸ')
      }
    } catch (error) {
      console.error('WebRTCè¿æ¥å¤±è´¥:', error)
    }
  }

  const disconnectWebRTC = () => {
    webrtcClient.value?.disconnect()
    webrtcClient.value = null
    webrtcConnected.value = false
    videoStream.value = null
  }

  const setVideoElement = (element: HTMLVideoElement) => {
    console.log('ğŸ“¹ videoStore.setVideoElementè¢«è°ƒç”¨, element:', element)
    currentVideoElement.value = element
    if (webrtcClient.value) {
      console.log('âœ… webrtcClientå­˜åœ¨ï¼Œæ­£åœ¨è®¾ç½®è§†é¢‘å…ƒç´ ')
      webrtcClient.value.setVideoElement(element)
    } else {
      console.log('âš ï¸ webrtcClientä¸å­˜åœ¨ï¼Œæ— æ³•è®¾ç½®è§†é¢‘å…ƒç´ ')
    }
  }

  const requestVideoStream = () => {
    console.log('ğŸ¬ è¯·æ±‚è§†é¢‘æµ - webrtcClient:', !!webrtcClient.value, 'selectedSourceId:', selectedSourceId.value)
    if (webrtcClient.value && selectedSourceId.value) {
      console.log('âœ… æ¡ä»¶æ»¡è¶³ï¼Œå‘é€request_offer')
      webrtcClient.value.requestVideoStream()
    } else {
      console.log('âŒ æ¡ä»¶ä¸æ»¡è¶³ - webrtcClientå­˜åœ¨:', !!webrtcClient.value, 'selectedSourceIdå­˜åœ¨:', !!selectedSourceId.value)
    }
  }

  // JPEGè§†é¢‘æ’­æ”¾å™¨ç›¸å…³æ–¹æ³•
  const setJpegVideoPlayer = (player: any) => {
    jpegVideoPlayer.value = player
    console.log('ğŸ¬ è®¾ç½®JPEGè§†é¢‘æ’­æ”¾å™¨:', !!player)
  }

  const handleJpegFrame = (jpegData: ArrayBuffer) => {
    const currentTime = performance.now()

    // è®¡ç®—å»¶è¿Ÿ
    if (lastFrameTimestamp.value > 0) {
      frameLatency.value = currentTime - lastFrameTimestamp.value
    }
    lastFrameTimestamp.value = currentTime

    // å‘é€åˆ°JPEGæ’­æ”¾å™¨
    if (jpegVideoPlayer.value) {
      jpegVideoPlayer.value.displayJpegFrame(jpegData)
      jpegVideoPlayer.value.updateLatency(frameLatency.value)

      // æ›´æ–°åˆ†æç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
      const recentResult = recentAnalysisResults.value[0]
      if (recentResult) {
        jpegVideoPlayer.value.updateDetections(recentResult.detections || [])
      }
    } else {
      console.warn('âš ï¸ JPEGè§†é¢‘æ’­æ”¾å™¨æœªè®¾ç½®')
    }
  }

  // ä»åç«¯è·å–æ¨¡å‹åˆ—è¡¨
  const fetchModels = async () => {
    try {
      const response = await fetch('/api/analyzer/models')
      const data = await response.json()
      if (data.success && data.data) {
        availableModels.value = data.data
        if (availableModels.value.length > 0 && !selectedModelId.value) {
          selectedModelId.value = availableModels.value[0].id
        }
      }
    } catch (error) {
      console.error('è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥:', error)
    }
  }

  // ä»åç«¯è·å–è§†é¢‘æºåˆ—è¡¨
  const fetchVideoSources = async () => {
    try {
      const response = await fetch('/api/analyzer/sources')
      const data = await response.json()
      if (data.success && data.data) {
        videoSources.value = data.data
        if (videoSources.value.length > 0 && !selectedSourceId.value) {
          selectedSourceId.value = videoSources.value[0].id
        }
      }
    } catch (error) {
      console.error('è·å–è§†é¢‘æºåˆ—è¡¨å¤±è´¥:', error)
    }
  }

  // åˆå§‹åŒ–
  const init = async () => {
    // åˆå§‹åŒ–WebSocketç”¨äºæ§åˆ¶å‘½ä»¤ï¼ŒWebRTCç”¨äºè§†é¢‘æµ
    console.log('ğŸš€ videoStore.init() - å¼€å§‹åˆå§‹åŒ–')
    connectWebSocket()
    console.log('ğŸ¯ æ­£åœ¨è¿æ¥WebRTC...')
    connectWebRTC()

    // ä»åç«¯è·å–è§†é¢‘æºåˆ—è¡¨
    console.log('ğŸ“¹ æ­£åœ¨è·å–è§†é¢‘æºåˆ—è¡¨...')
    await fetchVideoSources()

    // ä»åç«¯è·å–æ¨¡å‹åˆ—è¡¨
    console.log('ğŸ“¦ æ­£åœ¨è·å–æ¨¡å‹åˆ—è¡¨...')
    await fetchModels()

    console.log('âœ… videoStore.init() - åˆå§‹åŒ–å®Œæˆ')
  }

  return {
    // çŠ¶æ€
    videoSources,
    analysisResults,
    analysisTypes,
    selectedSourceId,
    selectedAnalysisType,
    connectionStatus,

    // æ¨¡å‹ç›¸å…³çŠ¶æ€
    availableModels,
    selectedModelId,
    isAnalyzing,

    // WebRTCçŠ¶æ€
    webrtcConnected,
    videoStream,
    currentVideoElement,

    // è®¡ç®—å±æ€§
    activeVideoSources,
    selectedSource,
    recentAnalysisResults,
    filteredModels,

    // æ–¹æ³•
    connectWebSocket,
    addVideoSource,
    updateVideoSource,
    removeVideoSource,
    startAnalysis,
    stopAnalysis,
    setSelectedSource,
    setSelectedAnalysisType,
    setSelectedModel,
    getAnalysisStatus,
    fetchModels,
    fetchVideoSources,

    // WebRTCæ–¹æ³•
    connectWebRTC,
    disconnectWebRTC,
    setVideoElement,
    requestVideoStream,

    // JPEGæ’­æ”¾å™¨æ–¹æ³•
    setJpegVideoPlayer,
    handleJpegFrame,

    init
  }
})