<template>
  <div class="jpeg-video-player">
    <div class="video-container" :style="containerStyle">
      <!-- Canvaså…ƒç´ ç”¨äºæ˜¾ç¤ºJPEGå¸§ -->
      <canvas
        ref="canvasRef"
        :width="canvasWidth"
        :height="canvasHeight"
        class="video-canvas"
      />

      <!-- è§†é¢‘æ§åˆ¶å åŠ å±‚ -->
      <div class="video-overlay">
        <!-- æ’­æ”¾çŠ¶æ€æŒ‡ç¤ºå™¨ -->
        <div class="status-indicator">
          <el-tag
            :type="isPlaying ? 'success' : 'info'"
            size="small"
            effect="dark"
          >
            {{ isPlaying ? `æ’­æ”¾ä¸­ ${fps.toFixed(1)}fps` : 'ç­‰å¾…æ•°æ®' }}
          </el-tag>
        </div>

        <!-- åˆ†æç»“æœå åŠ æ˜¾ç¤º -->
        <div
          v-if="showDetections && currentDetections.length > 0"
          class="detections-overlay"
        >
          <div
            v-for="(detection, index) in currentDetections"
            :key="index"
            class="detection-box"
            :style="getDetectionBoxStyle(detection)"
          >
            <span class="detection-label">
              {{ detection.class_name }} ({{ Math.round(detection.confidence * 100) }}%)
            </span>
          </div>
        </div>

        <!-- è§†é¢‘ä¿¡æ¯æ˜¾ç¤º -->
        <div class="video-info" v-if="showVideoInfo">
          <div class="info-item">åˆ†è¾¨ç‡: {{ currentWidth }}x{{ currentHeight }}</div>
          <div class="info-item">å¸§ç‡: {{ fps.toFixed(1) }} fps</div>
          <div class="info-item">å·²æ¥æ”¶: {{ frameCount }} å¸§</div>
          <div class="info-item">å»¶è¿Ÿ: {{ latency }}ms</div>
        </div>
      </div>

      <!-- æ— è§†é¢‘æ—¶çš„å ä½ç¬¦ -->
      <div v-if="!hasReceivedFrame" class="no-video-placeholder">
        <el-icon size="60"><Camera /></el-icon>
        <p>ç­‰å¾…JPEGè§†é¢‘æµ...</p>
        <p style="font-size: 12px; color: #999">é€šè¿‡WebRTC Data Channelä¼ è¾“</p>
      </div>
    </div>

    <!-- æ§åˆ¶æŒ‰é’® -->
    <div class="controls" v-if="showControls">
      <el-button-group>
        <el-button
          size="small"
          @click="togglePlay"
          :disabled="!hasReceivedFrame"
        >
          <el-icon><VideoPlay v-if="!isPlaying" /><VideoPause v-else /></el-icon>
        </el-button>

        <el-button
          size="small"
          @click="saveCurrentFrame"
          :disabled="!hasReceivedFrame"
        >
          <el-icon><Download /></el-icon>
          ä¿å­˜
        </el-button>

        <el-button
          size="small"
          @click="toggleDetections"
        >
          <el-icon><View /></el-icon>
          {{ showDetections ? 'éšè—' : 'æ˜¾ç¤º' }}æ£€æµ‹
        </el-button>

        <el-button
          size="small"
          @click="toggleVideoInfo"
        >
          <el-icon><InfoFilled /></el-icon>
          ä¿¡æ¯
        </el-button>
      </el-button-group>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, computed, onMounted, onUnmounted, nextTick } from 'vue'
import { Camera, VideoPlay, VideoPause, Download, View, InfoFilled } from '@element-plus/icons-vue'
import type { DetectionResult } from '@/types'

// Props
interface Props {
  width?: number
  height?: number
  showControls?: boolean
  showDetections?: boolean
  detections?: DetectionResult[]
}

const props = withDefaults(defineProps<Props>(), {
  width: 640,
  height: 480,
  showControls: true,
  showDetections: true,
  detections: () => []
})

// Emits
const emit = defineEmits<{
  frameReceived: [width: number, height: number]
  error: [message: string]
}>()

// å“åº”å¼æ•°æ®
const canvasRef = ref<HTMLCanvasElement | null>(null)
const isPlaying = ref(false)
const hasReceivedFrame = ref(false)
const showVideoInfo = ref(false)

// è§†é¢‘ç»Ÿè®¡ä¿¡æ¯
const frameCount = ref(0)
const fps = ref(0)
const latency = ref(0)
const currentWidth = ref(0)
const currentHeight = ref(0)
const currentDetections = ref<DetectionResult[]>([])

// FPSè®¡ç®—
const fpsCalculator = {
  frameTimestamps: [] as number[],
  lastUpdateTime: 0
}

// è®¡ç®—å±æ€§
const canvasWidth = computed(() => props.width)
const canvasHeight = computed(() => props.height)

const containerStyle = computed(() => ({
  width: `${props.width}px`,
  height: `${props.height}px`
}))

// æ–¹æ³•
const updateDetections = (detections: DetectionResult[]) => {
  if (props.showDetections) {
    currentDetections.value = detections || []
  }
}

const getDetectionBoxStyle = (detection: DetectionResult) => {
  // å°†æ£€æµ‹æ¡†åæ ‡è½¬æ¢ä¸ºCanvasä¸Šçš„ç›¸å¯¹ä½ç½®
  const scaleX = props.width / currentWidth.value
  const scaleY = props.height / currentHeight.value

  return {
    left: `${detection.bbox.x * scaleX}px`,
    top: `${detection.bbox.y * scaleY}px`,
    width: `${detection.bbox.width * scaleX}px`,
    height: `${detection.bbox.height * scaleY}px`,
  }
}

const calculateFPS = () => {
  const now = performance.now()
  fpsCalculator.frameTimestamps.push(now)

  // ä¿ç•™æœ€è¿‘1ç§’çš„æ—¶é—´æˆ³
  fpsCalculator.frameTimestamps = fpsCalculator.frameTimestamps.filter(
    timestamp => now - timestamp <= 1000
  )

  // æ¯500msæ›´æ–°ä¸€æ¬¡FPSæ˜¾ç¤º
  if (now - fpsCalculator.lastUpdateTime >= 500) {
    fps.value = fpsCalculator.frameTimestamps.length
    fpsCalculator.lastUpdateTime = now
  }
}

// æ˜¾ç¤ºJPEGå¸§
const displayJpegFrame = (jpegData: ArrayBuffer) => {
  if (!canvasRef.value) return

  try {
    const blob = new Blob([jpegData], { type: 'image/jpeg' })
    const imageUrl = URL.createObjectURL(blob)

    const img = new Image()
    img.onload = () => {
      const canvas = canvasRef.value!
      const ctx = canvas.getContext('2d')!

      // æ›´æ–°å½“å‰å¸§å°ºå¯¸
      currentWidth.value = img.width
      currentHeight.value = img.height

      // æ¸…é™¤ç”»å¸ƒ
      ctx.clearRect(0, 0, canvas.width, canvas.height)

      // ä¿æŒå®½é«˜æ¯”ç»˜åˆ¶å›¾åƒ
      const scale = Math.min(canvas.width / img.width, canvas.height / img.height)
      const scaledWidth = img.width * scale
      const scaledHeight = img.height * scale
      const x = (canvas.width - scaledWidth) / 2
      const y = (canvas.height - scaledHeight) / 2

      ctx.drawImage(img, x, y, scaledWidth, scaledHeight)

      // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
      frameCount.value++
      calculateFPS()
      hasReceivedFrame.value = true
      isPlaying.value = true

      // è§¦å‘äº‹ä»¶
      emit('frameReceived', img.width, img.height)

      // æ¸…ç†URLå¯¹è±¡
      URL.revokeObjectURL(imageUrl)
    }

    img.onerror = (error) => {
      console.error('âŒ JPEGå›¾åƒåŠ è½½å¤±è´¥:', error)
      emit('error', 'JPEGå›¾åƒåŠ è½½å¤±è´¥')
      URL.revokeObjectURL(imageUrl)
    }

    img.src = imageUrl

  } catch (error) {
    console.error('âŒ JPEGå¸§æ˜¾ç¤ºå¤±è´¥:', error)
    emit('error', 'JPEGå¸§æ˜¾ç¤ºå¤±è´¥: ' + (error as Error).message)
  }
}

// æ§åˆ¶æ–¹æ³•
const togglePlay = () => {
  isPlaying.value = !isPlaying.value
}

const saveCurrentFrame = () => {
  if (!canvasRef.value) return

  try {
    canvasRef.value.toBlob((blob) => {
      if (blob) {
        const url = URL.createObjectURL(blob)
        const link = document.createElement('a')
        link.href = url
        link.download = `frame_${Date.now()}.png`
        link.click()
        URL.revokeObjectURL(url)
      }
    }, 'image/png')
  } catch (error) {
    console.error('âŒ ä¿å­˜å¸§å¤±è´¥:', error)
    emit('error', 'ä¿å­˜å¸§å¤±è´¥')
  }
}

const toggleDetections = () => {
  // è§¦å‘çˆ¶ç»„ä»¶åˆ‡æ¢æ£€æµ‹æ˜¾ç¤º
}

const toggleVideoInfo = () => {
  showVideoInfo.value = !showVideoInfo.value
}

// æ¸…é™¤ç”»å¸ƒ
const clearCanvas = () => {
  if (canvasRef.value) {
    const ctx = canvasRef.value.getContext('2d')
    if (ctx) {
      ctx.clearRect(0, 0, canvasRef.value.width, canvasRef.value.height)
    }
  }
  hasReceivedFrame.value = false
  isPlaying.value = false
  frameCount.value = 0
  fps.value = 0
}

// æ›´æ–°å»¶è¿Ÿï¼ˆç”±çˆ¶ç»„ä»¶è°ƒç”¨ï¼‰
const updateLatency = (ms: number) => {
  latency.value = ms
}

// æš´éœ²æ–¹æ³•ç»™çˆ¶ç»„ä»¶
defineExpose({
  displayJpegFrame,
  updateDetections,
  updateLatency,
  clearCanvas
})

// ç”Ÿå‘½å‘¨æœŸ
onMounted(() => {
  console.log('ğŸ¬ JPEGè§†é¢‘æ’­æ”¾å™¨å·²æŒ‚è½½')
})

onUnmounted(() => {
  // æ¸…ç†èµ„æº
  clearCanvas()
})
</script>

<style scoped>
.jpeg-video-player {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 10px;
}

.video-container {
  position: relative;
  background-color: #000;
  border-radius: 8px;
  overflow: hidden;
  border: 2px solid var(--el-border-color);
}

.video-canvas {
  display: block;
  width: 100%;
  height: 100%;
  object-fit: contain;
}

.video-overlay {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  pointer-events: none;
}

.status-indicator {
  position: absolute;
  top: 10px;
  left: 10px;
  pointer-events: auto;
}

.detections-overlay {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
}

.detection-box {
  position: absolute;
  border: 2px solid #00ff00;
  background-color: rgba(0, 255, 0, 0.1);
  box-sizing: border-box;
}

.detection-label {
  position: absolute;
  top: -25px;
  left: 0;
  background-color: #00ff00;
  color: #000;
  padding: 2px 6px;
  font-size: 12px;
  border-radius: 3px;
  white-space: nowrap;
  font-weight: bold;
}

.video-info {
  position: absolute;
  top: 10px;
  right: 10px;
  background: rgba(0, 0, 0, 0.7);
  color: white;
  padding: 8px;
  border-radius: 4px;
  font-size: 12px;
  pointer-events: auto;
}

.info-item {
  margin-bottom: 2px;
}

.info-item:last-child {
  margin-bottom: 0;
}

.no-video-placeholder {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  color: #666;
  background: linear-gradient(45deg, #333 25%, transparent 25%),
              linear-gradient(-45deg, #333 25%, transparent 25%),
              linear-gradient(45deg, transparent 75%, #333 75%),
              linear-gradient(-45deg, transparent 75%, #333 75%);
  background-size: 20px 20px;
  background-position: 0 0, 0 10px, 10px -10px, -10px 0px;
}

.controls {
  display: flex;
  justify-content: center;
  margin-top: 10px;
}
</style>